# –ó–∞–¥–∞—á–∞: –ê–¥–∞–ø—Ç–∞—Ü–∏—è –≥–æ—Ç–æ–≤–æ–≥–æ AI –∞–≥–µ–Ω—Ç–∞ –ø–æ–∏—Å–∫–∞ (MVP 0)

## –û–ø–∏—Å–∞–Ω–∏–µ
–ê–¥–∞–ø—Ç–∞—Ü–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –ø—Ä–æ—Ç–æ—Ç–∏–ø–∞ AI –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–º–ø–∞–Ω–∏–π –ø–æ–¥ –Ω–∞—à—É –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.

## –¶–µ–ª—å
–ë—ã—Å—Ç—Ä–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≥–æ—Ç–æ–≤—ã–π AI –∞–≥–µ–Ω—Ç –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞.

## –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

### 1. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ AI Service (–º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è)
```
ai-service/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py          # FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
‚îÇ   ‚îú‚îÄ‚îÄ config.py        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
‚îÇ   ‚îú‚îÄ‚îÄ database.py      # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
‚îÇ   ‚îú‚îÄ‚îÄ search_agent.py  # –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–≥–µ–Ω—Ç
‚îÇ   ‚îî‚îÄ‚îÄ embeddings.py    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è embeddings
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env
‚îî‚îÄ‚îÄ README.md
```

### 2. requirements.txt (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π)
```
fastapi==0.108.0
uvicorn[standard]==0.25.0
python-dotenv==1.0.0
openai==1.6.1
asyncpg==0.29.0
httpx==0.25.2
pydantic==2.5.3
```

### 3. app/config.py
```python
from pydantic_settings import BaseSettings
from functools import lru_cache

class Settings(BaseSettings):
    # OpenAI
    openai_api_key: str
    openai_model: str = "gpt-4"
    embedding_model: str = "text-embedding-ada-002"
    
    # Database
    database_url: str
    
    # Service
    environment: str = "development"
    
    class Config:
        env_file = ".env"
        case_sensitive = False

@lru_cache()
def get_settings() -> Settings:
    return Settings()

settings = get_settings()
```

### 4. app/database.py
```python
import asyncpg
from app.config import settings

pool = None

async def init_db():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—É–ª–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π –∫ –ë–î"""
    global pool
    pool = await asyncpg.create_pool(settings.database_url)
    print("‚úÖ Database pool created")

async def close_db():
    """–ó–∞–∫—Ä—ã—Ç–∏–µ –ø—É–ª–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π"""
    global pool
    if pool:
        await pool.close()
        print("‚úÖ Database pool closed")

async def get_pool():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—É–ª–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π"""
    return pool
```

### 5. app/embeddings.py
```python
import openai
from app.config import settings
from typing import List

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ OpenAI
openai.api_key = settings.openai_api_key

async def generate_embedding(text: str) -> List[float]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è embedding –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
    try:
        if not text or not text.strip():
            # –í–æ–∑–≤—Ä–∞—Ç –Ω—É–ª–µ–≤–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞ –¥–ª—è –ø—É—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            return [0.0] * 1536
        
        response = await openai.embeddings.acreate(
            model=settings.embedding_model,
            input=text.strip()
        )
        
        return response.data[0].embedding
        
    except Exception as e:
        print(f"Error generating embedding: {e}")
        raise

async def generate_embeddings_batch(texts: List[str]) -> List[List[float]]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è embeddings –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤"""
    try:
        response = await openai.embeddings.acreate(
            model=settings.embedding_model,
            input=[t.strip() for t in texts if t and t.strip()]
        )
        
        return [item.embedding for item in response.data]
        
    except Exception as e:
        print(f"Error generating batch embeddings: {e}")
        raise
```

### 6. app/search_agent.py (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)
```python
import openai
from app.config import settings
from app.database import get_pool
from app.embeddings import generate_embedding
from typing import List, Dict, Any
import json

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ OpenAI
openai.api_key = settings.openai_api_key

class SearchAgent:
    """
    AI –∞–≥–µ–Ω—Ç –¥–ª—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∫–æ–º–ø–∞–Ω–∏–π.
    –ê–¥–∞–ø—Ç–∞—Ü–∏—è –≥–æ—Ç–æ–≤–æ–≥–æ –ø—Ä–æ—Ç–æ—Ç–∏–ø–∞.
    """
    
    def __init__(self):
        self.model = settings.openai_model
    
    async def search(self, query: str, filters: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞.
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ
            filters: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º
        """
        try:
            # –®–∞–≥ 1: –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ GPT
            intent = await self._analyze_query(query)
            
            # –®–∞–≥ 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è embedding –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
            query_embedding = await generate_embedding(query)
            
            # –®–∞–≥ 3: –ü–æ–∏—Å–∫ –≤ –ë–î
            if intent.get('search_type') == 'products':
                results = await self._search_products(query, query_embedding)
            else:
                results = await self._search_companies(query, query_embedding)
            
            # –®–∞–≥ 4: –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            ranked_results = await self._rank_and_explain(query, results, intent)
            
            return {
                'companies': ranked_results,
                'total': len(ranked_results),
                'query': query,
                'intent': intent,
            }
            
        except Exception as e:
            print(f"Search error: {e}")
            raise
    
    async def _analyze_query(self, query: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            response = await openai.chat.completions.acreate(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": """–¢—ã - –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –∞–Ω–∞–ª–∏–∑—É –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ B2B –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ.
                        
                        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∑–∞–ø—Ä–æ—Å –∏ –æ–ø—Ä–µ–¥–µ–ª–∏:
                        1. –ß—Ç–æ –∏—â–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –∫–æ–º–ø–∞–Ω–∏–∏ –∏–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã/—É—Å–ª—É–≥–∏
                        2. –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏ –∫—Ä–∏—Ç–µ—Ä–∏–∏
                        3. –û—Ç—Ä–∞—Å–ª—å –∏–ª–∏ —Å—Ñ–µ—Ä—É –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                        
                        –û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
                        {
                            "search_type": "companies" –∏–ª–∏ "products",
                            "keywords": ["–∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ 1", "–∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ 2"],
                            "industry": "–æ—Ç—Ä–∞—Å–ª—å –∏–ª–∏ null",
                            "intent": "–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è"
                        }
                        """
                    },
                    {"role": "user", "content": query}
                ],
                temperature=0.3,
                max_tokens=300,
            )
            
            content = response.choices[0].message.content
            return json.loads(content)
            
        except Exception as e:
            print(f"Query analysis error: {e}")
            return {
                "search_type": "companies",
                "keywords": [query],
                "industry": None,
                "intent": query
            }
    
    async def _search_companies(self, query: str, embedding: List[float]) -> List[Dict]:
        """–ü–æ–∏—Å–∫ –∫–æ–º–ø–∞–Ω–∏–π –≤ –ë–î (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π + —Ç–µ–∫—Å—Ç–æ–≤—ã–π)"""
        pool = await get_pool()
        
        # –ü–æ–∫–∞ –±–µ–∑ vector search (–¥–æ–±–∞–≤–∏–º –ø–æ–∑–∂–µ –≤ MVP 1)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –ø–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
        async with pool.acquire() as conn:
            rows = await conn.fetch("""
                SELECT 
                    id, 
                    full_name, 
                    inn, 
                    description, 
                    website,
                    phone,
                    email,
                    ts_rank(
                        to_tsvector('russian', full_name || ' ' || COALESCE(description, '')),
                        plainto_tsquery('russian', $1)
                    ) as rank
                FROM companies
                WHERE is_active = true
                  AND to_tsvector('russian', full_name || ' ' || COALESCE(description, '')) 
                      @@ plainto_tsquery('russian', $1)
                ORDER BY rank DESC
                LIMIT 20
            """, query)
            
            return [dict(row) for row in rows]
    
    async def _search_products(self, query: str, embedding: List[float]) -> List[Dict]:
        """–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –ø—Ä–æ–¥—É–∫—Ç—ã/—É—Å–ª—É–≥–∏"""
        pool = await get_pool()
        
        async with pool.acquire() as conn:
            rows = await conn.fetch("""
                SELECT DISTINCT ON (c.id)
                    c.id, 
                    c.full_name, 
                    c.inn, 
                    c.description, 
                    c.website,
                    c.phone,
                    c.email,
                    ps.name as matched_product,
                    ps.description as product_description,
                    ts_rank(
                        to_tsvector('russian', ps.name || ' ' || COALESCE(ps.description, '')),
                        plainto_tsquery('russian', $1)
                    ) as rank
                FROM companies c
                JOIN products_services ps ON c.id = ps.company_id
                WHERE c.is_active = true 
                  AND ps.is_active = true
                  AND to_tsvector('russian', ps.name || ' ' || COALESCE(ps.description, '')) 
                      @@ plainto_tsquery('russian', $1)
                ORDER BY c.id, rank DESC
                LIMIT 20
            """, query)
            
            return [dict(row) for row in rows]
    
    async def _rank_and_explain(
        self, 
        query: str, 
        results: List[Dict], 
        intent: Dict
    ) -> List[Dict]:
        """–†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π"""
        if not results:
            return []
        
        # –î–ª—è MVP 0 –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞–∫ –µ—Å—Ç—å
        # –í MVP 1 –¥–æ–±–∞–≤–∏–º AI –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
        for result in results:
            result['relevance_score'] = float(result.get('rank', 0))
            result['explanation'] = f"–ù–∞–π–¥–µ–Ω–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É: {query}"
        
        return results[:10]  # –¢–æ–ø 10 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∞–≥–µ–Ω—Ç–∞
search_agent = SearchAgent()
```

### 7. app/main.py
```python
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, Any
from contextlib import asynccontextmanager

from app.database import init_db, close_db
from app.search_agent import search_agent

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    print("üöÄ Starting AI Service...")
    await init_db()
    print("‚úÖ AI Service started")
    
    yield
    
    # Shutdown
    print("üõë Shutting down AI Service...")
    await close_db()
    print("‚úÖ AI Service stopped")

app = FastAPI(
    title="B2B AI Search Service (MVP 0)",
    description="–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π AI —Å–µ—Ä–≤–∏—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–º–ø–∞–Ω–∏–π",
    version="0.1.0",
    lifespan=lifespan
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic –º–æ–¥–µ–ª–∏
class SearchRequest(BaseModel):
    query: str
    filters: Optional[Dict[str, Any]] = None

class SearchResponse(BaseModel):
    companies: list
    total: int
    query: str
    intent: Optional[Dict[str, Any]] = None

# Health check
@app.get("/health")
async def health_check():
    return {
        "status": "ok",
        "service": "AI Search Service",
        "version": "0.1.0"
    }

# –ü–æ–∏—Å–∫
@app.post("/search", response_model=SearchResponse)
async def search_companies(request: SearchRequest):
    """
    –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –∫–æ–º–ø–∞–Ω–∏–π.
    
    –ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞:
    {
        "query": "–ò—â—É –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ IT –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –≤ –ú–æ—Å–∫–≤–µ"
    }
    """
    try:
        result = await search_agent.search(request.query, request.filters)
        return SearchResponse(**result)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

### 8. .env.example
```env
# OpenAI
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4
EMBEDDING_MODEL=text-embedding-ada-002

# Database
DATABASE_URL=postgresql://postgres:your_password@localhost:5432/b2b_mvp

# Service
ENVIRONMENT=development
```

## –ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏
- [ ] FastAPI —Å–µ—Ä–≤–∏—Å –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫
- [ ] –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] OpenAI API —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] Endpoint POST /search –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –∑–∞–ø—Ä–æ—Å—ã
- [ ] –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ GPT —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] –ü–æ–∏—Å–∫ –∫–æ–º–ø–∞–Ω–∏–π –≤ –ë–î —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç—Å—è —Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å—é
- [ ] Health check endpoint –¥–æ—Å—Ç—É–ø–µ–Ω

## –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
- –ó–∞–¥–∞—á–∞ 02-postgres-local-setup
- –ì–æ—Ç–æ–≤—ã–π –ø—Ä–æ—Ç–æ—Ç–∏–ø AI –∞–≥–µ–Ω—Ç–∞ (–∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç—Å—è)

## –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç
–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π (P0)

## –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏
4-6 —á–∞—Å–æ–≤ (—Å –∞–¥–∞–ø—Ç–∞—Ü–∏–µ–π –ø—Ä–æ—Ç–æ—Ç–∏–ø–∞)

## –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –∑–∞–ø—É—Å–∫—É

```bash
cd ai-service
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
cp .env.example .env
# –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å .env (–¥–æ–±–∞–≤–∏—Ç—å OPENAI_API_KEY)
uvicorn app.main:app --reload --port 8000
```

## –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```bash
# Health check
curl http://localhost:8000/health

# –ü–æ–∏—Å–∫
curl -X POST http://localhost:8000/search \
  -H "Content-Type: application/json" \
  -d '{"query": "–ò—â—É IT –∫–æ–º–ø–∞–Ω–∏—é"}'
```


